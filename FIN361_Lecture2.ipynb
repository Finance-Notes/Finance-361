{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0RkcCKTvegA"
      },
      "source": [
        "# **FINANCE 361**\n",
        "\n",
        "**Lecture 2**\n",
        "\n",
        "## **Statistical Regression vs Neural Networks**\n",
        "\n",
        "(The following Python code is non-examinable)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is used to facilitate discussion on statistical regressions and neural networks.\n",
        "\n",
        "\n",
        "*   The data utilized in the analysis does not meet the highest quality standards.\n",
        "*   The coding approach does not align with the industry's best practices.\n",
        "*   The code is designed to be easily understood and intuitive.\n",
        "\n"
      ],
      "metadata": {
        "id": "UgVVHqt_nsem"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNCk1YCgvhvN"
      },
      "source": [
        "### **Preliminary Step #1**\n",
        "\n",
        "\n",
        "*   Install the yfinance Python package\n",
        "  *   To download market data from Yahoo! Finance API\n",
        "  *   See: https://pypi.org/project/yfinance/\n",
        "\n",
        "*   Install the Keras Python package\n",
        "  *   A Python interface for artificial neural networks\n",
        "  *   See: https://keras.io/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P-7B4RAytMm"
      },
      "outputs": [],
      "source": [
        "pip install yfinance"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras"
      ],
      "metadata": {
        "id": "YNyuEa9-VLOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb4gPK1uvk9I"
      },
      "source": [
        "### **Preliminary Step #2**\n",
        "\n",
        "\n",
        "\n",
        "*   Import the required packages into Python for our models\n",
        "  * Numpy:  https://numpy.org\n",
        "  * Pandas: https://pandas.pydata.org\n",
        "  * Matplotlib: https://matplotlib.org\n",
        "  * Statsmodels: https://www.statsmodels.org/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGY869mKvqV1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "import keras\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "from keras import backend as K\n",
        "\n",
        "print(keras.__version__)\n",
        "\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 0: Define the parameters**\n",
        "\n",
        "Defining our parameters now ensures that everything is consistent for the remainder of the script."
      ],
      "metadata": {
        "id": "eSciL1P9UkMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Define the parameters\n",
        "\n",
        "NUM_DAYS_HISTORY = 1260      # Approximate number of trading days in five years\n",
        "\n",
        "NUM_DAYS_FORECAST = 126     # Approximate number of trading days in six months"
      ],
      "metadata": {
        "id": "Tr9V4v2TUWWN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 1: Plotting and Accuracy Definitions**\n",
        "\n",
        "In Python, function definitions create reusable blocks of code that perform specific tasks or represent data structures."
      ],
      "metadata": {
        "id": "afWOORNIlkQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def actual_vs_predicted_plot(actual, predicted, NUM_DAYS_HISTORY, NUM_DAYS_FORECAST):\n",
        "\n",
        "  \"\"\"\n",
        "  The actual_vs_predicted_plot function visualizes a comparison between actual values and predicted values,\n",
        "  dividing predictions into in-sample (up to NUM_DAYS_HISTORY) and out-of-sample (beyond NUM_DAYS_HISTORY) forecasts.\n",
        "  \"\"\"\n",
        "\n",
        "  # Plot settings\n",
        "  fig, ax = plt.subplots(figsize=(14, 7))\n",
        "  plt.title('Actual vs Predicted Values')\n",
        "  plt.xlabel('')\n",
        "  plt.ylabel('')\n",
        "\n",
        "\n",
        "  # Historical prices\n",
        "  ax.plot(actual, color='black', label='Actual')\n",
        "  ax.plot(predicted[:NUM_DAYS_HISTORY],\n",
        "          color='Blue',\n",
        "          label='Predicted (in-sample)')\n",
        "  ax.plot(predicted[NUM_DAYS_HISTORY:],\n",
        "          color='Red',\n",
        "          label='Predicted (out-of-sample)')\n",
        "\n",
        "  # plt.legend()\n",
        "  plt.tight_layout()\n",
        "  plt"
      ],
      "metadata": {
        "id": "fAITP8D2lj7T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def r_squared_score(actual, predicted):\n",
        "\n",
        "  \"\"\"\n",
        "  The r_squared_score function calculates and prints the R-squared value,\n",
        "  a statistical measure of how close the data are to the fitted regression line,\n",
        "  using actual and predicted values.\n",
        "  \"\"\"\n",
        "\n",
        "  r_squared = r2_score(actual, predicted)\n",
        "\n",
        "  print(f\"R-squared value: {r_squared}\")"
      ],
      "metadata": {
        "id": "3yr9QONglqiz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Step 2: Get / Generate the data**\n",
        "\n",
        "Two sets of data are available:\n",
        "\n",
        "\n",
        "1.   The first data set represents a simple linear relationship (e.g., y = 2x + 1), which is split it into training and test sets.\n",
        "2.   The second data set comprises market data downloaded from Yahoo Finance.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-bhDD5OkVc83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "j76sNvMp03Sb"
      },
      "outputs": [],
      "source": [
        "# Sample Data: Simple linear relationship (for example, y = 2x + 1)\n",
        "\n",
        "data = {'x': np.arange(0, NUM_DAYS_HISTORY+NUM_DAYS_FORECAST), 'y': (np.arange(0, NUM_DAYS_HISTORY+NUM_DAYS_FORECAST) * 2 + 1)}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df_train = df[:NUM_DAYS_HISTORY]\n",
        "df_test = df[NUM_DAYS_HISTORY:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Market Data\n",
        "\n",
        "\"\"\"\n",
        "stock = yf.download('GME', period=str(NUM_DAYS_HISTORY+NUM_DAYS_FORECAST+504)+'d', interval='1d')  # SMMT\n",
        "stock['Ri'] = np.log(stock['Adj Close']/(stock['Adj Close'].shift(1)))\n",
        "stock['Ri_vol_delta'] = np.log(stock['Volume']/(stock['Volume'].shift(1)))\n",
        "stock['Ri_spread'] = (stock['High'] - stock['Low'])/stock['Adj Close']\n",
        "\n",
        "spx = yf.download('^GSPC', period=str(NUM_DAYS_HISTORY+NUM_DAYS_FORECAST+504)+'d', interval='1d')\n",
        "spx['Rm'] = np.log(spx['Adj Close']/(spx['Adj Close'].shift(1)))\n",
        "spx['Rm_vol_delta'] = np.log(spx['Volume']/(spx['Volume'].shift(1)))\n",
        "spx['Rm_spread'] = (spx['High'] - spx['Low'])/spx['Adj Close']\n",
        "\n",
        "tbill_data = yf.download('^IRX', period=str(NUM_DAYS_HISTORY+NUM_DAYS_FORECAST+504)+'d', interval='1d')\n",
        "tbill_data['Rf'] = (1+tbill_data['Adj Close'] / 100) ** (1/252) - 1\n",
        "\n",
        "tbill_data['Rf_spread'] = (tbill_data['High'] - tbill_data['Low'])/stock['Adj Close']\n",
        "\n",
        "df = pd.merge(stock, spx, left_index=True, right_index=True, how='inner')\n",
        "df = pd.merge(df, tbill_data, left_index=True, right_index=True, how='inner')\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df = df[['Ri', 'Rm', 'Rf', 'Ri_vol_delta', 'Ri_spread', 'Rm_vol_delta', 'Rm_spread', 'Rf_spread']]\n",
        "\n",
        "df['y'] = df['Ri'] - df['Rf']\n",
        "df['x'] = df['Rm'] - df['Rf']\n",
        "\n",
        "print('\\n', df.describe())\n",
        "\n",
        "df_train = df[-(NUM_DAYS_HISTORY+NUM_DAYS_FORECAST):-NUM_DAYS_FORECAST]\n",
        "df_test = df[-NUM_DAYS_FORECAST:]\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "qk9r36w0b_5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Regression Model**\n",
        "\n",
        "Our benchmark model is the lineear regression model estimated with OLS.\n",
        "\n",
        "The model is available from the statsmodels package.\n",
        "\n",
        "> statsmodels.regression.linear_model.OLS\n",
        "\n"
      ],
      "metadata": {
        "id": "nGj1HAMjW78F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indep_var = ['x']\n",
        "\n",
        "# Assuming df_train['y'] is your dependent variable and df_train['x'] your independent variable\n",
        "y = df_train['y']\n",
        "\n",
        "# Add a constant to the model (for the intercept)\n",
        "X = sm.add_constant(df_train[indep_var])\n",
        "# X = np.ones(len(df_train['y']))  # This creates an array of ones\n",
        "\n",
        "# Fit the model\n",
        "# Make sure the dependent variable (y) is the first argument\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary of the model\n",
        "print(model.summary())"
      ],
      "metadata": {
        "id": "KvNn-YHyW7Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assessing the accuracy of the model**"
      ],
      "metadata": {
        "id": "dfcXlk5V87lx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(sm.add_constant(df[indep_var]))\n",
        "y_pred_is = model.predict(sm.add_constant(df_train[indep_var]))\n",
        "y_pred_oos = model.predict(sm.add_constant(df_test[indep_var]))\n",
        "\n",
        "actual_vs_predicted_plot(df[['y']], y_pred, NUM_DAYS_HISTORY, NUM_DAYS_FORECAST)\n",
        "\n",
        "r_squared_score(df[['y']], y_pred)"
      ],
      "metadata": {
        "id": "CzQt9z2diXkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn!**\n",
        "\n",
        "\n",
        "\n",
        "*   Conduct the regression analysis using only the intercept term; what do we observe?\n",
        "*   Add a non-linear term to the simulated dataset. Afterwards, (1) execute the linear regression analysis and (2) attempt to include the non-linear aspect into the regression model.\n",
        "\n"
      ],
      "metadata": {
        "id": "fzcrSD_KvLmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Neural Network Model**\n",
        "\n",
        "We'll begin by defining a simple neural network with one unit and a linear activation function, using the Keras package:\n",
        "\n",
        "https://keras.io/guides/sequential_model/\n",
        "\n",
        "For optimization visualizations, see here:\n",
        "\n",
        "https://github.com/j-w-yun/optimizer-visualization"
      ],
      "metadata": {
        "id": "84smbgBYVv_J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-D3IndL0vaRL"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "\n",
        "def neural_netork(input_dim):\n",
        "  model = Sequential()\n",
        "\n",
        "  # Add a single Dense layer (perceptron) with 1 unit, input shape of 1, and a linear activation function\n",
        "  # Since the linear activation function acts as an identity function, it's equivalent to what you need\n",
        "  model.add(Dense(1, input_dim=input_dim, activation='linear'))\n",
        "\n",
        "  # Second hidden layer\n",
        "  # model.add(Dense(64, activation='relu'))\n",
        "\n",
        "  # Third hidden layer\n",
        "  # model.add(Dense(1, activation='linear'))\n",
        "\n",
        "  # Compile the model\n",
        "  # The optimizer is set to 'adam', and the loss function to 'mean_squared_error'\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='mean_squared_error'\n",
        "                )\n",
        "\n",
        "  # Summary of the model to see its structure\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "oy3-Dhe29W6c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1jLpMRW0HuQ"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "# Using df['x'] as input and df['y'] as the target\n",
        "\n",
        "indep_var = ['x']\n",
        "\n",
        "model = neural_netork(len(indep_var))\n",
        "history = model.fit(df_train[indep_var].values, df_train['y'].values,\n",
        "                    epochs=100,\n",
        "                    batch_size=10,\n",
        "                    validation_split=0,\n",
        "                    verbose=0,\n",
        "                    shuffle=True\n",
        "                    )\n",
        "\n",
        "\n",
        "# Plotting the training (and validation) loss\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "if 'val_loss' in history.history:\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Printing the NNs parameters**"
      ],
      "metadata": {
        "id": "LRF3UViB9O8t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-SkEeku1XS4"
      },
      "outputs": [],
      "source": [
        "# Print the weights and biases\n",
        "\n",
        "\"\"\"\n",
        "This code iterates through each layer of a model, retrieves and prints the weights and biases for every layer,\n",
        "specifying each layer's position in the sequence.\n",
        "\"\"\"\n",
        "\n",
        "for layer in model.layers:\n",
        "    weights, biases = layer.get_weights()\n",
        "    print(f\"Weights of layer {model.layers.index(layer)+1}: {weights}\")\n",
        "    print(f\"Biases of layer {model.layers.index(layer)+1}: {biases}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Assessing the accuracy of the model**"
      ],
      "metadata": {
        "id": "aDml_lnH9MVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "y_pred = pd.Series(model.predict(df[indep_var]).flatten())  # Flatten is used to ensure the prediction array shape matches the target array\n",
        "y_pred.index = df.index\n",
        "y_pred_is = pd.Series(model.predict(df_train[indep_var]).flatten())\n",
        "y_pred_is.index = df_train.index\n",
        "y_pred_oos = pd.Series(model.predict(df_test[indep_var]).flatten())\n",
        "y_pred_oos.index = df_test.index\n",
        "\n",
        "actual_vs_predicted_plot(df[['y']], y_pred, NUM_DAYS_HISTORY, NUM_DAYS_FORECAST)\n",
        "\n",
        "r_squared_score(df[['y']], y_pred)"
      ],
      "metadata": {
        "id": "DVjw4czy27VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn!**\n",
        "\n",
        "With linear and non-linear simulated data:\n",
        "*   Add a two more layers to the NN; what do we observe?\n",
        "*   Add a non-linear activation function to the model; what do we observe?\n"
      ],
      "metadata": {
        "id": "ffr_Ilcp9gU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the market data to fit and train the regression and NN models, respectively.\n",
        "\n",
        "*   What do we learn about benefits / disadvantages of each?\n",
        "*   What do we learn about the behavior of asset prices and financial markets?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fAemyPpo-hWK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}